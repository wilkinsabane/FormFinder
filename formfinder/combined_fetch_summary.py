#!/usr/bin/env python
"""
Combined Fetch Summary Generator

This script reads the individual summary files from historical_fetcher.py and upcoming_fetcher.py
and creates a comprehensive overview of all fetched data.

Usage:
    python combined_fetch_summary.py [--output OUTPUT_FILE]

Options:
    --output OUTPUT_FILE    Path to save the combined summary (default: data/logs/combined_fetch_summary.json)
"""

import os
import json
import argparse
import logging
from datetime import datetime
from typing import Dict, Any, List, Optional

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def load_summary_file(file_path: str) -> Optional[Dict[str, Any]]:
    """Load a summary file and return its contents as a dictionary.
    
    Args:
        file_path: Path to the summary file
        
    Returns:
        Dictionary containing the summary data or None if file doesn't exist or is invalid
    """
    try:
        if not os.path.exists(file_path):
            logger.warning(f"Summary file not found: {file_path}")
            return None
            
        with open(file_path, 'r') as f:
            data = json.load(f)
        return data
    except Exception as e:
        logger.error(f"Error loading summary file {file_path}: {e}")
        return None


def generate_combined_summary(historical_summary: Optional[Dict[str, Any]], 
                             upcoming_summary: Optional[Dict[str, Any]],
                             fetch_summary: Optional[Dict[str, Any]]) -> Dict[str, Any]:
    """Generate a combined summary from individual summary files.
    
    Args:
        historical_summary: Data from historical_fetch_summary.json
        upcoming_summary: Data from upcoming_fetch_summary.json
        fetch_summary: Data from fetch_summary.json (generated by EnhancedDataFetcher)
        
    Returns:
        Dictionary containing the combined summary data
    """
    combined = {
        'timestamp': datetime.now().isoformat(),
        'historical_data': {},
        'upcoming_data': {},
        'file_statistics': {},
        'leagues': {}
    }
    
    # Add historical data if available
    if historical_summary:
        combined['historical_data'] = {
            'timestamp': historical_summary.get('timestamp'),
            'season': historical_summary.get('season'),
            'leagues_processed': historical_summary.get('leagues_processed', 0),
            'total_matches': historical_summary.get('total_matches', 0),
            'new_matches': historical_summary.get('new_matches', 0),
            'total_standings': historical_summary.get('total_standings', 0),
            'countries': historical_summary.get('countries', []),
            'teams_count': historical_summary.get('teams_count', 0)
        }
        
        # Add league-specific historical data
        for league_name, match_count in historical_summary.get('leagues_with_matches', {}).items():
            if league_name not in combined['leagues']:
                combined['leagues'][league_name] = {}
            combined['leagues'][league_name]['historical_matches'] = match_count
            
        for league_name, standings_count in historical_summary.get('leagues_with_standings', {}).items():
            if league_name not in combined['leagues']:
                combined['leagues'][league_name] = {}
            combined['leagues'][league_name]['standings'] = standings_count
    
    # Add upcoming data if available
    if upcoming_summary:
        combined['upcoming_data'] = {
            'timestamp': upcoming_summary.get('timestamp'),
            'leagues_processed': upcoming_summary.get('leagues_processed', 0),
            'total_fixtures': upcoming_summary.get('total_fixtures', 0),
            'countries': upcoming_summary.get('countries', []),
            'total_teams': upcoming_summary.get('total_teams', 0)
        }
        
        # Add league-specific upcoming data
        for league_name, fixture_count in upcoming_summary.get('league_fixture_counts', {}).items():
            if league_name not in combined['leagues']:
                combined['leagues'][league_name] = {}
            combined['leagues'][league_name]['upcoming_fixtures'] = fixture_count
    
    # Add file statistics if available from fetch_summary.json
    if fetch_summary:
        combined['file_statistics'] = {
            'timestamp': fetch_summary.get('timestamp'),
            'total_files': fetch_summary.get('total_files', 0),
            'total_size_mb': fetch_summary.get('total_size_mb', 0)
        }
        
        # Add detailed league data from fetch_summary
        for league_id, league_data in fetch_summary.get('leagues', {}).items():
            # Try to find league name from historical or upcoming data
            league_name = None
            for name in combined['leagues'].keys():
                if str(league_id) in name:  # Simple heuristic to match league ID in name
                    league_name = name
                    break
            
            if not league_name:
                league_name = f"League-{league_id}"
                
            if league_name not in combined['leagues']:
                combined['leagues'][league_name] = {}
                
            # Add file-based statistics
            combined['leagues'][league_name].update({
                'id': league_id,
                'historical_file_matches': league_data.get('historical_matches', 0),
                'standings_file_entries': league_data.get('standings', 0),
                'fixtures_file_entries': league_data.get('fixtures', 0),
                'files_created': league_data.get('files_created', [])
            })
    
    return combined


def main():
    """Main function to generate combined fetch summary."""
    parser = argparse.ArgumentParser(description='Generate combined fetch summary from individual summary files.')
    parser.add_argument('--output', default=None, help='Path to save the combined summary')
    args = parser.parse_args()
    
    # Determine paths
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    logs_dir = os.path.join(base_dir, 'data', 'logs')
    
    # Ensure logs directory exists
    os.makedirs(logs_dir, exist_ok=True)
    
    # Default output path
    if not args.output:
        args.output = os.path.join(logs_dir, 'combined_fetch_summary.json')
    
    # Load summary files
    historical_summary_path = os.path.join(logs_dir, 'historical_fetch_summary.json')
    upcoming_summary_path = os.path.join(logs_dir, 'upcoming_fetch_summary.json')
    fetch_summary_path = os.path.join(logs_dir, 'fetch_summary.json')
    
    logger.info(f"Loading summary files from {logs_dir}")
    historical_summary = load_summary_file(historical_summary_path)
    upcoming_summary = load_summary_file(upcoming_summary_path)
    fetch_summary = load_summary_file(fetch_summary_path)
    
    # Generate combined summary
    logger.info("Generating combined summary")
    combined_summary = generate_combined_summary(historical_summary, upcoming_summary, fetch_summary)
    
    # Save combined summary
    try:
        with open(args.output, 'w') as f:
            json.dump(combined_summary, f, indent=2)
        logger.info(f"Combined summary saved to {args.output}")
        
        # Print summary statistics
        print("\n" + "=" * 80)
        print("COMBINED FETCH SUMMARY")
        print("=" * 80)
        print(f"Generated at: {combined_summary['timestamp']}")
        
        if 'historical_data' in combined_summary and combined_summary['historical_data']:
            hist = combined_summary['historical_data']
            print(f"\nHistorical Data (as of {hist.get('timestamp')})")
            print(f"  Season: {hist.get('season')}")
            print(f"  Leagues processed: {hist.get('leagues_processed')}")
            print(f"  Total matches: {hist.get('total_matches')}")
            print(f"  New matches added: {hist.get('new_matches')}")
            print(f"  Total standings entries: {hist.get('total_standings')}")
            print(f"  Countries represented: {len(hist.get('countries', []))}")
            print(f"  Teams count: {hist.get('teams_count')}")
        
        if 'upcoming_data' in combined_summary and combined_summary['upcoming_data']:
            upc = combined_summary['upcoming_data']
            print(f"\nUpcoming Data (as of {upc.get('timestamp')})")
            print(f"  Leagues processed: {upc.get('leagues_processed')}")
            print(f"  Total fixtures: {upc.get('total_fixtures')}")
            print(f"  Countries represented: {len(upc.get('countries', []))}")
            print(f"  Teams count: {upc.get('total_teams')}")
        
        if 'file_statistics' in combined_summary and combined_summary['file_statistics']:
            stats = combined_summary['file_statistics']
            print(f"\nFile Statistics (as of {stats.get('timestamp')})")
            print(f"  Total files: {stats.get('total_files')}")
            print(f"  Total size: {stats.get('total_size_mb'):.2f} MB")
        
        print("\nLeague Statistics:")
        for league_name, league_data in sorted(combined_summary['leagues'].items()):
            print(f"  {league_name}:")
            for key, value in league_data.items():
                if key != 'files_created':
                    print(f"    {key}: {value}")
            if 'files_created' in league_data and league_data['files_created']:
                print(f"    files: {', '.join(league_data['files_created'])}")
        
        print("=" * 80)
        
    except Exception as e:
        logger.error(f"Error saving combined summary: {e}")


if __name__ == '__main__':
    main()